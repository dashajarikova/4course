{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лин регрессия хороша тем, можно применить метод градиентного спуска из-за дифференцируемости + выполнена теорема Гаусса-Маркова. С деревьями ничего такого сделать не получится и утверждать тоже ничего нельзя по поводу ее оценки. Имея это ввиду, получается, что лин регрессия лучше дерева решений, когда нужно аппроксимировать функцию, а не просто небольшой набор признаков. То есть лин регрессия будет нормально вести себя на области определения всей функции, а не только на тех участках, где есть тестовая выборка. Кроме того, дерево начинает себя очень плохо вести, когда появляется слишком много признаков - оно разрастается вглубь так, что поиск по нему теперь задача непростая. Лин регрессия же, в свою очередь, будет просто дифференцироваться и идти к точке минимума, это быстрая задача."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48192, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train['review']\n",
    "y_train = df_train['target']\n",
    "\n",
    "tfidf = TfidfVectorizer(max_df=0.5, min_df=10)\n",
    "X_train = tfidf.fit_transform(X_train)\n",
    "\n",
    "X_test = tfidf.transform(df_test['review'])\n",
    "y_test = df_test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "KNC = KNeighborsClassifier(n_neighbors=2)\n",
    "KNC.fit(X_train, y_train)\n",
    "y_pred = KNC.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline(model, X_train, X_test, y_train, y_test, hyper_parametrs):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        valid = GridSearchCV(model, param_grid = hyper_parametrs, cv = 5)\n",
    "        valid.fit(X_train, y_train)\n",
    "\n",
    "        model = valid.best_estimator_\n",
    "        print (f\"f1_score on train : {model.score(X_train, y_train)} \\nAfter regularization: {valid.best_score_} \\nBest params: {valid.best_params_} \\nTest: {model.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score on train:  0.4517960209485149\n"
     ]
    }
   ],
   "source": [
    "model_pipeline(KNeighborsClassifier(), X_train, y_train, X_test, y_test, paramsKNN) #недокрутилось"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramsKNN = {'n_neighbors': range(1, 10), 'weights' : ['uniform', 'distance'], 'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2314787619481402"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNC = KNeighborsClassifier(weights = 'distance') #лучшее что нашлось вручную\n",
    "KNC.fit(X_train, y_train)\n",
    "y_pred = KNC.predict(X_test)\n",
    "f1_score(y_test, y_pred, average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = OneVsRestClassifier(SVC()).fit(X_train, y_train) #недокрутилось\n",
    "y_pred = clf.predict (X_test)\n",
    "f1_score(y_test, y_pred, average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ovo = OneVsOneClassifier(SVC()).fit(X, y)\n",
    "y_pred = clf.predict (X_test)\n",
    "f1_score(y_test, y_pred, average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OutputCodeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_samples=100, n_features=4,n_informative=2, n_redundant=0,random_state=0, shuffle=False)\n",
    "clf = OutputCodeClassifier(estimator=RandomForestClassifier(random_state=0),random_state=0).fit(X, y)\n",
    "clf.predict(X_test)\n",
    "f1_score(y_test, y_pred, average = 'macro')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
